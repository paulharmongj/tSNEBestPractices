---
title: "Formal Writeup"
author: "Paul Harmon"
date: "7/25/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
source("OutlierCompFunctions.R")
library(ggplot2)
library(readr)
library(tibble)
library(dplyr)
library(tidyr)
library(janitor)
library(magrittr)
library(knitr)
library(Rtsne)
library(robustHD)
library(GGally)
library(stringr)
library(plotly)
library(R.utils)
library(vegan)
library(mnormt)



Generate_Holdout_Maps <- function(data, j, ...){  
  
  #hold out a single row of the data (in the jth row)
  #note - have to remove, as t-SNE doesn't like NAs
  data_holdout <- data[-j,]
  
  #calculate distances FIRST
  data_dist <- dist(data_holdout)
  
  #### Creates Maps (based on several methods)
  
  #generate the classical MDS
  mds1 <- cmdscale(data_dist, k = 2)
  
  #generate the t-SNE map and store x,y in map list
  x <- Rtsne(data_dist, perplexity = perplexity, pca = pca_options, is_distance = TRUE)
  
  return(list(mds = mds1, tsne = x$Y))
}


```




# Introduction

Consider the problem of visualizing multivariate data (or potentially multivariate in many or high-dimensions).  In many cases, it is useful to generate a 2 or 3-D mapping of some higher-dimensional space, projecting the high-dimensional data into an ordination that can be directly visualized. There are many methods that exist to accomplish this task, ranging from tools such as classicial multidimensional scaling (MDS) to more modern tools like t-distributed Stochastic Neighbor Embedding. 

Unlike regression or classification, most tools for dimension reduction and higher-dimensional data visualization are unsupervised, meaning that they do not take advantage of some marked response variable; rather, they capitalize on the signal present in a set of features and produce a data-driven result.  In regression models, we have a suite of tools to measure and assess unusual observations related to response vs. model predictions. 

In a regression model, the estimated coefficients or predictions might be affected in meaningful fashion by the inclusion or exclusion of a single point - such points are referred to as influential (Cook, 1977).  A suite of tools have been developed to identify and measure the impact of influential points on the results of regression models. Tools like t-SNE and MDS are also succeptible to abberant data values, much in the same way that a regression model might be succeptible to outliers and, specifically, influential points.




## Goal 

The goal of this method is to develop a diagnostic that can be used to help identify influential points and potentially quantify how much they impact the resulting mapping, and create a tool that can be used with any mapping technique.   Additionally, this method can be used to assess the sensitivity of each method to influential points and the impact that sensititivy might have on how an end user might want to interpret the resulting map produced.  Note that while robustness to influential points might at first seem like a positive trait for an ordination method, masking distinctly different observations in a mapping may have negative consequences as well. 


This document overviews the statistical methodology we have developed to identify influential points that, when excluded from a dataset, can meaningfully impact the shape of an ordination created from data. We overview our methodology step by step. 


# Methods

This document assesses the effect of multivariate outliers on the maps produced by two methods: classical multidimensional scaling and t-SNE. In general, we seek to identify either **multivariate outliers** (or groups of them) which, for some reason, cause large differences in the shape of the resulting ordination. The methods rely on a few different ideas.  First, PERMANOVA (Anderson, 2001) is a non-parametric, multivariate version of Analysis of Variance (ANOVA) that relies on a pseduo-F test to compare within-group and between group similarities based on a specified distance (dissimilarity) measure. Unlike ANOVA, PERMANOVA makes use of permutation tests to draw inferences without assuming distributions of test statistics. 

Second, distance matrices contain information on point-to-point distances (or dissimilarities) and, when vectorized, the correlation of the distance matrices measures similarity of two configurations (Mantel's test (Mantel, 1967) makes use of this approach to assess correlation between distance matrices). 

Third, correlations (or similarities) can be converted to distances; one such metric for doing this is $\sqrt{2(1-r_{ij})}$ (James et al, 2013). 

Finally, correlations can be computed using pairwise complete observations to leverage all available information to estimate correlations in the presence of some missing data values. 


Our Permanova-based approach is as follows: 

1. For each observation in the dataset, remove it, and generate a map in 2 dimensions from the resulting (n-1) observations for a selected ordination method.  (For accounting purposes, it may make sense to keep the nx1 structure but replace the holdout observation with NA). 
2. Generate a distance matrix of the nx1 by 2 matrix. Do this for each of the held-out observations. 
3. Generate a pairwise-complete correlation matrix from the combination of these vectorized distances that measures similarity of distances (where available).
4. Convert that correlation matrix (of all the hold-out vectorized distance matrices) into a distance matrix using a $$\sqrt{2(1-r_{ij})}$$ (James et al, 2013). 
5. Apply non-parametric PERMANOVA tests for each holdout observation - this means that on a 100-observation dataset, you apply 100 individual tests where each test uses an independent variable that is equal to 1 for the index of the holdout observation and 0 elsewhere. The hypotheses are specified as such: 

+ $H_0$: No differences in map with observation j removed vs. those without j removed 
+ $H_a$: Some difference in map with observation j removed

We will discuss correcting p-values for multiple testing later, although currently our plan is to assess using Benjamini-Hochberg False Discovery Rate or Bonferroni corrections (or something similar, assuming that the results are based on p-values as in the Bonferroni Outlier test (Cook & Weisberg, 1982)). We would expect that if the maps are suitably distorted, or *influenced* by a single point, the resulting p-value for the jth adonis test would be small. 




# Assessment on Data

## Token Example 

We first step through an example of the method as utilized on a relatively small dataset, to show how the algorithm works. Let's consider an example with 63 observations simulated from a multivariate normal distribution. 

The code below simulates the data with some clearly abberant values. 

```{r simulate_token_data, include = TRUE, message = FALSE, warning = FALSE}
set.seed(34536)
g1 <- rmnorm(n = 10, mean = rep(20, 10), diag(25, 10)) %>%
  t() %>%
  data.frame()
g2 <- rmnorm(n = 10, mean = rep(50, 20), diag(25, 20)) %>%
  t() %>%
  data.frame()
g3 <- rmnorm(n = 10, mean = rep(80, 30), diag(25, 30)) %>%
  t() %>%
  data.frame()


yes_structure <- rbind(g1, g2, g3) %>%
  data.frame() %>%
  mutate(Group = c(rep("1", 10), rep("2", 20), rep("3", 30)))

yes_structure_scale <- lapply(yes_structure[,1:10], scale) %>% as_tibble()

## adds outliers in the last 1 index (simulating from normal based on 5 sd's from mean)
add_outliers <- rbind(rnorm(10, 5, .5)) %>% as_tibble()
names(add_outliers) <- names(yes_structure_scale)


yes_structure_final <- bind_rows(yes_structure_scale, add_outliers) 
yes_structure_final$Group <- c(yes_structure$Group, rep("Outlier",1))
```


1. For each observation in the dataset, remove it, and generate a (t-SNE or MDS) map in 2 dimensions from the resulting (n-1) observations.  (For accounting purposes, it may make sense to keep the nx1 structure but replace the holdout observation with NA). The code below shows this as it pertains to the "multipermanova" function that I have written - it makes use of a function called "insert" from R.utils that adds NAs for each index that is held out. 

```{r, eval = TRUE, message = FALSE, warning = FALSE}
#initializes some stuff 
perplexity = 10
data = yes_structure_final
n <- nrow(data)
  maplist <- list()
  cmdlist <- list()
  
#generate maps on holdout data
  for(j in 1:n){
    
    temp <- Generate_Holdout_Maps(data, j)
    cmdlist[[j]] <- temp$mds
    maplist[[j]] <- temp$tsne
    
  }

# Insert NAs into the holdout indices 
  maplist_new <- list()
  cmdlist_new <- list()
  

#replaces holdouts with NAs
for(j in 1:length(maplist)){
    #create temporary vectors with NAs for each of the XY coordingates
    tempX <- R.utils::insert(maplist[[j]][,1], j, NA)
    tempY <- R.utils::insert(maplist[[j]][,2], j, NA)
    
    tempcmdX <- R.utils::insert(cmdlist[[j]][,1], j, NA)
    tempcmdY <- R.utils::insert(cmdlist[[j]][,2], j, NA)
    
    maplist_new[[j]] <- tibble(X = tempX, Y = tempY)
    cmdlist_new[[j]] <- tibble(X = tempcmdX, Y = tempcmdY)
}


#prints out the maps
maplist_new[[1]] %>% head()

plot(maplist_new[[1]], pch = 20, main = "Example of maplist (t-SNE), Observation 1 Held Out")

```


2. Generate a distance matrix of the n by 2 matrix. Do this for each of the held-out observations. 

3. Vectorize the distance matrix and generate a correlation matrix(Pearson correlation based on pairwise-complete observations) from the combination of these vectorized distances.


We vectorize distance matrices in the following way, where $d12$ refers to the distance between the first and second observations (in the map). I'm ignoring the upper/lower triangle symmetry in this example. As an example, here's what this looks like in a very simplistic 3 observation case, when the first observation is held out. 

$$\mathbf{Dist(X_{nxn})} = \left[\begin{array}
{rrr}
NA & NA & NA \\
NA & 0 & d_{23} \\
NA & d_{32} & 0 
\end{array}\right]
$$

The vectorized form would be: 
$$vec(\mathbf{c(Dist(X)))^T} = \left[\begin{array}
{r}
NA & NA & NA &
NA & 0 & d_{32} &
NA & d_{23} & 0
\end{array}\right]
$$
Then, the matrix used to compare distance matrices is as follows, where each column comes from the ith holdout map. Note that the below notation reads: $d_{23, -1}$ is the distance between observations 2 and 3 on the map that holds out the 1st observation. 

$$ \mathbf{Cor(Dist(X))} = \left[\begin{array}
{rrr}
NA & d_{12, -2} & d_{13,-3} \\
NA & NA & d_{23,-3} \\
NA & d_{31,-2} & NA \\
NA & NA & ...\\
0 & NA & .\\
d_{32,-1} & NA & .\\
NA & d_{13,-2} & .\\
d_{23,-1} & NA & .\\
0 & 0 & .\\
\end{array}\right]
$$



Because of the holdout NAs, we do not have complete cases to compare so instead we use pairwise-complete observations. We can see a visual representation of the NAs for a sample of the distance matrices below: 

```{r}
#vectorizes the distances and outputs a list of vectorized distance matrices 
  distmat_list <- lapply(maplist_new, dist)
  distmat_list_cmd <- lapply(cmdlist_new, dist)
  
  
#levelplot(as.matrix(distmat_list[[1]]), main = paste0("NA Pattern for ",1, "st Holdout"))
#levelplot(as.matrix(distmat_list[[3]]), main = paste0("NA Pattern for ",3, "rd Holdout"))
#levelplot(as.matrix(distmat_list[[5]]), main = paste0("NA Pattern for ",5, "th Holdout"))


image(as.matrix(distmat_list[[3]]), main = "NA Pattern for 3rd Holdout", col = hcl.colors(4)) 

```





The code chunk below shows both steps simultaneously. 

```{r, eval = TRUE}
 #vectorizes the distances and outputs a list of vectorized distance matrices 
  dist_list <- lapply(maplist_new, vectorize_dist)
  dist_list_cmd <- lapply(cmdlist_new, vectorize_dist)
  
  
  
  ## takes the vectorized distance matrices and binds the columns into a single data frame - to build correlation matrix
  
  dist_mat <- dist_list %>% as_tibble(.name_repair = "minimal")
  dist_mat_cmd <- dist_list_cmd %>% as_tibble(.name_repair = "minimal")
  
  #prints out the data frame of vectorized distance matrices to show what we're looking at
  head(dist_mat)
  
  #dimensions are n*(n-1)/2 since the distance matrix is triangular - see below
  dim(dist_mat)
  
```

We calculate the correlation matrix from the above: 

```{r}
  
  
  #Generates the correlation matrix based on pairwise complete observations, and pearson correlation
  
  #tsne
  cormat <- cor(dist_mat, use = "pairwise.complete.obs", method = "pearson")
  cormat %>% dim()
  
  #cmd
  cormat_cmd <- cor(dist_mat_cmd, use = "pairwise.complete.obs", method = "pearson")
  cormat_cmd %>% dim()
  

```


4. Convert that correlation matrix (of all the hold-out vectorized distance matrices) into a distance matrix using the result that $D_{-i,-j} = \sqrt{2(1-r_{-i,-j})}$. Note that here, we expect that all the correlation values are greater than 0 - and as shown, they are. 

*Note also that with this new distance matrix, we can actually create 2D visualizations (maps) from the distance matrix, creating a "map-of-maps" to show which of the ordinations are different from the rest. (Similarly, you could cluster maps or perform any distance-based method on this matrix to explore differences in the holdout ordinations).* 

```{r}
## sanity check - these are all greater than 0
cormat %>% min()
##generate distance on correlation matrix
  cordist <- sqrt(2*(1-cormat)) %>% as.dist()
  cordist_cmd <- sqrt(2*(1-cormat_cmd)) %>% as.dist()
```


5. Apply non-parametric PERMANOVA tests for each holdout observation, using an indicator that is 1 for the holdout observation and 0 for all others.  Cycle the indicator for each index - so you will apply $n$ individual tests. 

In the code below, the data do not change - the calls to 'adonis' change only in that the index of the "1" for the indicator variable chanegs at each iteration. Thus, the indicator for the first holdout observation is [1,0,0,...] and so on and so forth. 

*Note that in some cases for Adonis, it may be possible to have more permutations than possible combinations of 0's and 1's - meaning that picking a number of permuations just re-samples the $n+1$ different unique permutations of the indicator which has a single $1$ and $0$'s in all the other indices (there are only* $n+1$ *pseudo-F statistics that are unique). To be more efficient with this permutation strategy so that we do not sample more than necessary, we specify a permutation matrix rather than passing a raw number of permuations*.  


```{r}
  nperms = 1000
  model_list <- list()
  model_list_cmd <- list()
  
 
  
  
 for(j in 1: nrow(as.matrix(cordist))){
    #generate the indicator variable for each feature
    indicator_df <- rep(0, nrow(maplist_new[[1]])) %>% as.data.frame()
    indicator_df_cmd <- rep(0, nrow(cmdlist_new[[1]])) %>% as.data.frame()
    
    names(indicator_df) <- names(indicator_df_cmd) <- "Indicator"
    indicator_df$Indicator[j] = 1
    indicator_df_cmd$Indicator[j] = 1
    
    
     ## create the permutation matrix
  #initialize
permat1 <- matrix(0, nrow = length(indicator_df$Indicator), ncol = length(indicator_df$Indicator))
permat1[1,] <- 1:length(indicator_df$Indicator)

for(i in 2:nrow(permat1)){
  permat1[i,] <- c(i:length(indicator_df$Indicator), 1:(i-1))
}
    
    
    #each item in the list is an Adonis test using the indicator for the holdout variable
    model_list[[j]] <- adonis(cordist ~ Indicator, data = indicator_df, permutations = permat1, parallel = 2)
    model_list_cmd[[j]] <- adonis(cordist_cmd ~ Indicator, data = indicator_df_cmd, permutations =  permat1)
    
    
  }
  
```


Note that in the Adonis function, we do obtain a few negative pseudo F-statistic values in certain cases. These are the null values based on the permutations used. This seems to occur only for the MDS data - in the cases where we do see negative values, they are quite close to 0. The sums of squares equivalent in PERMANOVA for the treatment is found by subtraction and the equivalent to the error sums of squares must be exceeding the total sums of squares (slightly, by a rounding error). 


```{r}

#from t-SNE
model_list[[1]]

model_list[[1]]$f.perms %>% min()
model_list[[1]]$f.perms %>% as.data.frame() %>% ggplot(aes(V1)) + geom_histogram(bins = 20) + ggtitle("Ex: Permutation Distribution: tSNE, bins = 20")

#from cmd - an example with negatives included (note that they are all the same value )
model_list_cmd[[1]]
model_list_cmd[[1]]$f.perms %>% min()
model_list_cmd[[1]]$f.perms[which(model_list_cmd[[1]]$f.perms<0)]
model_list_cmd[[1]]$f.perms %>% as.data.frame() %>% ggplot(aes(V1)) + geom_histogram(bins = 20) + ggtitle("Ex: Permutation Distribution: MDS, bins = 20")


```




# Appendix 

## Outliers and Influential Points

Similarly, the resulting maps produced by ordination methods like MDS, t-SNE and the like can be impacted by the inclusion or exclusion of points. In short, an "influential" point in a lower dimensional mapping can be defined as one that, when excluded, drives meaningful differences in the ordination method that lead to a different shaped map as compared to when that point is included. 

Difference between outliers and influential points. 

**talk about influence functions** (Joliffe and cited papers)

Joliffe (2002) overviews tools for identifying influential observations in Pricipal Component Analysis, which is a related dimension-reducting technique to MDS (at least in a Euclidean setting).  However, the literature on more recently-developed methods lacks a similar metric, most notably one that can be used or compared across different mapping methods. 

This section overviews some work into identifying multivariate outliers that we've looked into.  We have not found much in the way of users applying Mantel tests or Permanova-type tests on t-SNE or Classical MDS results in the way that we are thinking about things.  In fact, much of the literature around robustness and outliers centers on dealing with the problem by modifying the dimension reduction technique rather than identifying it.  

Blouvshtein and Cohen-Or (2018) analyzed the effect of outliers on the maps produced by classical multidimensional scaling methods.  In general, these methods are not particularly robust to the effects of multivariate outlier.  They propose a method to detect outliers prior to the generation of the MDS map so that they can be removed from the data. Their method involves treating the distances input to the algorithm as edges of a complete graph that connects each data point. 

These edges $d1, d2, d3$ can then be used to form triangles - in general, outliers tend to *break* the triangle inequality and inliers tend to satisfy it. They recommend a rule to examine the histogram H of $b$, the number of edges of broken triangles, and generate a threshold $\phi$ that is intended to identify inliers vs. outliers. 


Two other papers, including Forrero and Giannakis (2012) as well as Kong et al. (2019) frame the problem in a slightly different way. They consider a penalized *stress* metric for optimization, utilizing regularization to better identify outlier points.  In both cases, they are able to identify outliers using a majorization-minimization procedure that iteratively produce more outlier-robust maps of the lower-dimensional embedding of interest. 













